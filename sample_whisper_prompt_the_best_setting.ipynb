{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# sample whisper promptping"
      ],
      "metadata": {
        "id": "rWFcgMrwey0-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tj8QAo61zqMB"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/Hasan-Naseer/whisperX.git@release/latest-faster-whisper-version\n",
        "!pip install ctranslate2==4.4.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install libcudnn8 libcudnn8-dev"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-Sz9dptnSsc",
        "outputId": "84724219-9ada-436c-c38b-b95e1782e485"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  libcudnn8 libcudnn8-dev\n",
            "0 upgraded, 2 newly installed, 0 to remove and 20 not upgraded.\n",
            "Need to get 885 MB of archives.\n",
            "After this operation, 2,380 MB of additional disk space will be used.\n",
            "Get:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libcudnn8 8.9.7.29-1+cuda12.2 [444 MB]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libcudnn8-dev 8.9.7.29-1+cuda12.2 [440 MB]\n",
            "Fetched 885 MB in 9s (96.3 MB/s)\n",
            "Selecting previously unselected package libcudnn8.\n",
            "(Reading database ... 124926 files and directories currently installed.)\n",
            "Preparing to unpack .../libcudnn8_8.9.7.29-1+cuda12.2_amd64.deb ...\n",
            "Unpacking libcudnn8 (8.9.7.29-1+cuda12.2) ...\n",
            "Selecting previously unselected package libcudnn8-dev.\n",
            "Preparing to unpack .../libcudnn8-dev_8.9.7.29-1+cuda12.2_amd64.deb ...\n",
            "Unpacking libcudnn8-dev (8.9.7.29-1+cuda12.2) ...\n",
            "Setting up libcudnn8 (8.9.7.29-1+cuda12.2) ...\n",
            "Setting up libcudnn8-dev (8.9.7.29-1+cuda12.2) ...\n",
            "update-alternatives: warning: forcing reinstallation of alternative /usr/include/x86_64-linux-gnu/cudnn_v9.h because link group libcudnn is broken\n",
            "update-alternatives: using /usr/include/x86_64-linux-gnu/cudnn_v8.h to provide /usr/include/cudnn.h (libcudnn) in manual mode\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F95rCzFzw1Dz"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub.utils import _runtime\n",
        "_runtime._is_google_colab = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JJkFPuiyeECk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "suuS5_HTt3Xa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92cced03-4952-4e8b-8e06-6da6e411d82b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pyannote/audio/core/io.py:43: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.\n",
            "  torchaudio.set_audio_backend(\"soundfile\")\n",
            "/usr/local/lib/python3.11/dist-packages/pyannote/audio/pipelines/speaker_verification.py:43: UserWarning: torchaudio._backend.get_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.\n",
            "  backend = torchaudio.get_audio_backend()\n",
            "/usr/local/lib/python3.11/dist-packages/pyannote/audio/pipelines/speaker_verification.py:45: UserWarning: Module 'speechbrain.pretrained' was deprecated, redirecting to 'speechbrain.inference'. Please update your script. This is a change from SpeechBrain 1.0. See: https://github.com/speechbrain/speechbrain/releases/tag/v1.0.0\n",
            "  from speechbrain.pretrained import (\n",
            "/usr/local/lib/python3.11/dist-packages/pyannote/audio/pipelines/speaker_verification.py:53: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.\n",
            "  torchaudio.set_audio_backend(backend)\n",
            "/usr/local/lib/python3.11/dist-packages/pyannote/audio/tasks/segmentation/mixins.py:37: UserWarning: `torchaudio.backend.common.AudioMetaData` has been moved to `torchaudio.AudioMetaData`. Please update the import path.\n",
            "  from torchaudio.backend.common import AudioMetaData\n"
          ]
        }
      ],
      "source": [
        "import whisperx\n",
        "import gc\n",
        "\n",
        "device = \"cuda\"\n",
        "audio_file = \"/content/drive/MyDrive/REDC/Test/fn000049_1_003.wav\"\n",
        "batch_size = 8 # reduce if low on GPU mem\n",
        "compute_type = \"float16\" # change to \"int8\" if low on GPU mem (may reduce accuracy)\n",
        "\n",
        "# 1. Transcribe with original whisper (batched)\n",
        "#model = whisperx.load_model(\"large-v2\", device, compute_type=compute_type,initial_prompt='dat da dat')\n",
        "\n",
        "# save model to local path (optional)\n",
        "# model_dir = \"/path/\"\n",
        "# model = whisperx.load_model(\"large-v2\", device, compute_type=compute_type, download_root=model_dir)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "TvssOKd29K9k",
        "outputId": "035196eb-5350-488a-86fd-b23a83f87129"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.5.0.post0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../usr/local/lib/python3.11/dist-packages/whisperx/assets/pytorch_model.bin`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
            "Model was trained with torch 1.10.0+cu102, yours is 2.5.1+cu124. Bad things might happen unless you revert torch to 1.x.\n",
            "[{'text': ' hij geeft ze allemaal hij hij geeft ze allemaal een naam', 'start': 0.009, 'end': 4.053}]\n"
          ]
        }
      ],
      "source": [
        "import whisperx\n",
        "model = whisperx.load_model(\"large-v3\", device, language='nl',compute_type=compute_type, asr_options={\"hotwords\":None,\"initial_prompt\": \"eerst ee rst eer st ehij geeft ze allemaal een naam eerste was hhij geeft ze allema ehij geeft ze allemaal een naamt et p lagened plad gen flagen plagen dat vond maar tje maar maarte maart t maartje wel leuk maar l eu k loek luk maar naar maar toen het pesten pe te sten werd is ze mevrouw fre f r e d d e r fre dder fledder vledder gaan hel pen h e l p e n gaan helpen hand gebaren handgebaren\"})\n",
        "audio_file = \"/content/drive/MyDrive/REDC/Trim_Jasmin_Testing_Audio/fn000503/1.wav\"\n",
        "audio = whisperx.load_audio(audio_file)\n",
        "result = model.transcribe(audio=audio,batch_size=batch_size)\n",
        "print(result[\"segments\"]) # before alignment\n",
        "\n",
        "#print(result) # before alignment"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = model.transcribe(audio=audio,batch_size=batch_size)\n",
        "print(result[\"segments\"]) # before alignment"
      ],
      "metadata": {
        "id": "Am6vS9LHOWoc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# normalization"
      ],
      "metadata": {
        "id": "qSdRn6KNeuA-"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R2JYwCDUewPb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P2r9k5L7_W6c"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "import json\n",
        "\n",
        "Reformat_path = \"/content/drive/MyDrive/REDC/Jasmin_Child_Reformat_SanneAnno/\"\n",
        "children_data_path = \"/content/drive/MyDrive/REDC/JASMIN_textgrid/\"\n",
        "child_speaker_file = os.path.join(children_data_path+\"sprekers_informatie.xlsx\")\n",
        "child_data = pd.read_excel(child_speaker_file, index_col=0, usecols = np.arange(0,11))\n",
        "\n",
        "#long word can lead to index error in word_transcripiton\n",
        "\n",
        "\n",
        "\n",
        "DUTCH_NORMALIZATION = {\n",
        "    \"okee\": \"ok\", \"oke\": \"ok\", \"okey\": \"ok\", \"OKEE\": \"ok\", \"OKE\": \"ok\",\n",
        "    \"OKEY\": \"ok\", \"MIJN\": \"mijn\", \"mn\": \"mijn\", \"m'n\": \"mijn\", \"M'N\": \"mijn\", \"mjn\": \"mijn\",\n",
        "    \"'t\": \"het\", \"'T\": \"het\", \"'n\": \"een\", \"Een\": \"een\", \"EEN\": \"een\", \"z'n\": \"zijn\", \"zn\": \"z'n\",\n",
        "    \"'m\":\"hem\",\n",
        "    \"d'r\": \"daar\", \"dr\": \"daar\",\n",
        "    \"'s\": \"s\", \"zo'n\": \"zoon\",\n",
        "    \"'k\": \"ik\", \"'K\": \"ik\",\n",
        "    \"uh\": \"\", \"ggg\":\"\",\"mmm\":\"\",\n",
        "    \"s nachts\": \"s'nachts\",\n",
        "}\n",
        "\n",
        "def normalize_Dutch_string(input_string):\n",
        "    normalized_string = input_string\n",
        "    for key, value in DUTCH_NORMALIZATION.items():\n",
        "        normalized_string = normalized_string.replace(key, value)\n",
        "    return normalized_string\n",
        "\n",
        "def normalize_long_words(input_string):\n",
        "    normalized_string = input_string\n",
        "    for key, value in Long_word.items():\n",
        "        normalized_string = normalized_string.replace(key, value)\n",
        "    return normalized_string\n",
        "\n",
        "def read_phone_file(filename):\n",
        "    phone = []\n",
        "    with open(filename, 'r') as file:\n",
        "        for line in file:\n",
        "            # Split each line into key and value\n",
        "            phone.append(line.strip())\n",
        "\n",
        "    return \" \".join(phone)\n",
        "\n",
        "def reverse(input_string):\n",
        "    txt = input_string.split(\" \") [::-1]\n",
        "    return \" \".join(txt)\n",
        "\n",
        "def text_norm_all(s):\n",
        "    # Convert to lowercase\n",
        "    s = s.lower()\n",
        "\n",
        "    # Replace tag_a words\n",
        "    #s = s.replace(\"<tag_a>\", \"<unk>\")  # Assuming <tag_a> is the tag to be replaced\n",
        "    s = s.replace(\"*n\", \"\")  # Remove *a\n",
        "    s = s.replace(\"*a\", \"\")  # Remove *a\n",
        "    s = s.replace(\"*u\", \"\")  # Remove *a\n",
        "    s = s.replace(\"*s\", \"\")  # Remove *a\n",
        "    s = s.replace(\"*v\", \"\")  # Remove *\n",
        "\n",
        "    # Remove punctuation\n",
        "    punctuation = \".?!,-\"\n",
        "    for p in punctuation:\n",
        "        s = s.replace(p, \"\")\n",
        "\n",
        "    s = s.replace(\"â€™\", \"'\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    s =  normalize_Dutch_string(s)\n",
        "\n",
        "\n",
        "    return s"
      ]
    }
  ]
}